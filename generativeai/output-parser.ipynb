{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e02c918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A black hole is a region of spacetime with gravity so strong that nothing, not even light, can escape it. First predicted by Einstein’s general theory of relativity in 1915, its existence has since been confirmed by decades of observational evidence. Black holes form primarily from the gravitational collapse of massive stars or through mergers of dense objects. They are characterized by an event horizon—the boundary beyond which escape is impossible—and often host accretion disks and relativistic jets. Modern techniques\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "load_dotenv()\n",
    "#open source model,  not use the bydefault structured data\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen3-Coder-Next\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=100,\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "# first prompt details report\n",
    "template1=PromptTemplate(\n",
    "    template='Write a detailed report on the following topic: {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "#second prompt ->summary\n",
    "template2=PromptTemplate(\n",
    "    template='Write a write a 5 line summary on the following text ./n {text}',\n",
    "    input_variables=['text']\n",
    ")\n",
    "# prompt1 =template1.invoke({'topic':'black hole'})\n",
    "# result = model.invoke(prompt1)\n",
    "\n",
    "# prompt2 = template2.invoke({'text':result.content})\n",
    "# summary = model.invoke(prompt2)\n",
    "# summary.content\n",
    "#instead of doing this one we use the string output parser to directly get the summary without the need of the second prompt\n",
    "parser  = StrOutputParser()\n",
    "chain =template1 | model | parser |template2 | model | parser\n",
    "result = chain.invoke({'topic':'black hole'})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd84c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af51f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
