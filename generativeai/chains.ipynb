{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e44b6a76",
   "metadata": {},
   "source": [
    "TODAY WE ARE LEARNING ABOUT CHAINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31c0886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROK_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_KEY\")\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen3-Coder-Next\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=100,\n",
    ")\n",
    "\n",
    "model = ChatHuggingFace(llm=llm)\n",
    "model = init_chat_model(\"google_genai:gemini-2.5-flash-lite\")\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Generate 5 interesting facts about {topic}\",\n",
    "    input_variables=[\"topic\"],\n",
    ")\n",
    "parser = StrOutputParser()\n",
    "chain =  prompt| model| parser\n",
    "result = chain.invoke({\"topic\":\"cricket\"})\n",
    "print(result)\n",
    "graph = chain.get_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7318b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a 5-pointer summary of the provided text on cricket:\n",
      "\n",
      "*   **Origins and Evolution:** Cricket originated in England during the medieval period and has evolved over centuries, with key developments in the 18th and 19th centuries leading to standardized rules and the establishment of the MCC as the custodian of the Laws.\n",
      "*   **Gameplay and Objective:** The core objective is for one team to score more runs than the other by hitting a ball bowled by the opposing team and running between wickets, while the fielding team aims to dismiss batsmen through various methods.\n",
      "*   **Key Elements and Rules:** The game involves specific equipment like the pitch, wickets, bat, and ball, and players such as batsmen, bowlers, wicket-keepers, and fielders. Common dismissals include bowled, caught, LBW, and run out.\n",
      "*   **Formats and Tournaments:** Cricket is played in different formats like Test (five-day), ODI (50-over), and T20 (20-over), each with distinct strategies and appeal. Major tournaments include the ICC Cricket World Cup, ICC T20 World Cup, The Ashes, and prominent franchise leagues like the IPL.\n",
      "*   **Global Reach and Cultural Significance:** Cricket is particularly popular in Commonwealth countries and evokes immense passion, contributing significantly to economies and social cohesion, while also facing challenges in balancing formats and expanding its global reach.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_KEY\")\n",
    "model = init_chat_model(\"google_genai:gemini-2.5-flash-lite\")\n",
    "Prompt1 = PromptTemplate(\n",
    "    template=\"Generate  a detailed report on {topic}\",\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "Prompt2 = PromptTemplate(\n",
    "    template =\"Generate a 5 pointer summary from the following text\\n {text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = Prompt1 | model | Prompt2 | model | parser\n",
    "result = chain.invoke({\"topic\":\"cricket\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527b0a5e",
   "metadata": {},
   "source": [
    "PARALLEL CHAINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96ec9a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the merged document, combining your JavaScript notes and quiz:\n",
      "\n",
      "**JavaScript Notes & Quiz**\n",
      "\n",
      "**Notes:**\n",
      "\n",
      "*   **What**: JavaScript is a high-level, interpreted, and versatile programming language, originally created in 1995 by Brendan Eich.\n",
      "*   **Role**: It is the core language of the web, working in conjunction with HTML (for structure) and CSS (for styling) to add interactivity to web pages. This interactivity can manifest as animations, form validation, API calls, and more.\n",
      "*   **Execution**: JavaScript primarily runs within browser engines (such as V8 or SpiderMonkey). Its execution model is single-threaded, event-driven, and non-blocking, powered by the event loop.\n",
      "\n",
      "**Quiz:**\n",
      "\n",
      "**Q1: When was JavaScript created?**\n",
      "A1: JavaScript was created in 1995 by Brendan Eich.\n",
      "\n",
      "**Q2: What are the primary roles of HTML, CSS, and JavaScript in building web applications?**\n",
      "A2: HTML defines the structure of a webpage, CSS handles presentation and layout, and JavaScript brings functionality.\n",
      "\n",
      "**Q3: What is the primary execution model of JavaScript?**\n",
      "A3: JavaScript follows a single-threaded, event-driven, non-blocking execution model powered by the event loop.\n",
      "\n",
      "**Q4: With which framework can developers build scalable REST APIs, microservices, and real-time chat systems?**\n",
      "A4: With Node.js, developers can build scalable REST APIs, microservices, and real-time chat systems.\n",
      "\n",
      "**Q5: What is the name of the package manager that provides access to millions of reusable libraries for JavaScript development?**\n",
      "A5: npm (Node Package Manager) provides access to millions of reusable libraries for JavaScript development.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROK_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_KEY\")\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen3-Coder-Next\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=100,\n",
    ")\n",
    "\n",
    "\n",
    "prompt1 = PromptTemplate(\n",
    "    template = \"Generate a  short and simple Notes from the following text\\n {text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "prompt2 = PromptTemplate(\n",
    "    template = \"Generate five short question answer from the given text\\n {text}\",\n",
    "    input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "prompt3 = PromptTemplate(\n",
    "    template = \"Merge the provided notes and quiz into a single document\\n Notes:{notes} and quiz:{quiz}\",\n",
    "    input_variables=[\"notes\",\"quiz\"] \n",
    ")\n",
    "model1 = ChatHuggingFace(llm=llm)\n",
    "model2 = init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "model3 = init_chat_model(\"google_genai:gemini-2.5-flash-lite\")\n",
    "parser = StrOutputParser()\n",
    "parallel_chain = RunnableParallel({\n",
    "    'notes':prompt1 |model1 | parser,\n",
    "    'quiz':prompt2 | model2 | parser\n",
    "    \n",
    "    }\n",
    ")\n",
    "merge_chain = prompt3 | model3 | parser\n",
    "chain = parallel_chain | merge_chain\n",
    "text=\"\"\"JavaScript is a versatile, high-level, interpreted programming language that plays a central role in modern software development, especially in web applications. It was created in 1995 by Brendan Eich and has since evolved into one of the most widely used languages in the world. JavaScript is primarily known as the scripting language of the web, working alongside HTML and CSS to build interactive user interfaces—where HTML defines the structure of a webpage, CSS handles presentation and layout, and JavaScript brings functionality such as dynamic content updates, animations, form validations, API integrations, and real-time user interactions. Executed inside browser engines like Google Chrome’s V8 or Firefox’s SpiderMonkey, JavaScript follows a single-threaded, event-driven, non-blocking execution model powered by the event loop, allowing it to handle asynchronous operations efficiently without freezing the user interface. Over time, with the introduction of Node.js, JavaScript expanded beyond the browser into backend development, enabling developers to build scalable REST APIs, microservices, real-time chat systems, and full-stack applications using a single language. The language supports multiple programming paradigms, including procedural, functional, and prototype-based object-oriented programming, giving developers flexibility in designing applications. Modern ECMAScript (ES6 and beyond) introduced powerful features such as let and const for block scoping, arrow functions, template literals, destructuring, spread/rest operators, modules, classes, and async/await, significantly improving code readability and maintainability. JavaScript also has a massive ecosystem with frontend frameworks like React, Angular, and Vue; backend frameworks like Express and NestJS; mobile development through React Native; and desktop applications via Electron. With npm (Node Package Manager), developers gain access to millions of reusable libraries that accelerate development. Due to its cross-platform capability, continuous standardization, strong community support, and ability to power everything from simple websites to complex enterprise systems, JavaScript remains a foundational technology and an essential skill in the global software development landscape\"\"\"\n",
    "result = chain.invoke({'text':text})\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184a799d",
   "metadata": {},
   "source": [
    "CONDITIONAL CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69e7e6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I'm so sorry to hear that our product didn't meet your expectations and broke after a single use. I'm also disappointed to hear that our customer service didn't provide the level of support you deserved. Your feedback is invaluable to us, and I'd like to make things right.\n",
      "\n",
      "Can you please contact me directly so we can discuss possible solutions, such as a replacement or a refund? I'll also make sure to pass on your concerns to our customer service team so we can improve our support for future customers.\n",
      "\n",
      "Additionally, I'd like to ask for some more specific details about the issue you experienced, such as the product model and the circumstances surrounding the breakage. This will help us identify any potential design or manufacturing issues.\n",
      "\n",
      "Thank you for taking the time to share your concerns with us. We value your feedback and appreciate the opportunity to make things right.\"\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from langchain.chat_models import init_chat_model\n",
    "# from langchain_core.prompts import PromptTemplate\n",
    "# from langchain_core.output_parsers import PydanticOutputParser\n",
    "# from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "# from langchain_core.runnables import RunnableParallel, RunnableBranch, RunnableLambda\n",
    "# from pydantic import BaseModel,Field\n",
    "# from typing_extensions import Optional,Literal\n",
    "# load_dotenv()\n",
    "# os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROK_API_KEY\")\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_KEY\")\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"Qwen/Qwen3-Coder-Next\",\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=100,\n",
    "# )\n",
    "\n",
    "# class Feedback(BaseModel):\n",
    "#     sentiment:Literal['positive','negative','netural']=Field(description='Give the sentiment of the feedback')\n",
    "\n",
    "\n",
    "# parser = PydanticOutputParser(pydantic_object=Feedback)\n",
    "\n",
    "\n",
    "\n",
    "# # model1 = ChatHuggingFace(llm=llm)\n",
    "# model2 = init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "# # model1 = init_chat_model(\"google_genai:gemini-2.5-flash-lite\")\n",
    "\n",
    "\n",
    "# prompt1 = PromptTemplate(\n",
    "#     template = \"Classify the sentiment of the following feedback as positive , negative or neutral\\n {feedback} \\n {format_instruction}\",\n",
    "#     input_variables=[\"feedback\"],\n",
    "#     partial_variables={'format_instruction':parser.get_format_instructions()}\n",
    "# )\n",
    "\n",
    "# prompt2 = PromptTemplate(\n",
    "#     template=\"Write an appropriate response to this positive feedback\\n {feedback}\",\n",
    "#     input_variables={\"feedback\"}\n",
    "# )\n",
    "\n",
    "# prompt3 = PromptTemplate(\n",
    "#     template=\"Write an appropriate response to this negative feedback\\n {feedback}\",\n",
    "#     input_variables={\"feedback\"}\n",
    "# )\n",
    "# classification_chain = prompt1 |model2 | parser\n",
    "# postivechain = prompt2 | model2 |parser\n",
    "# negativechain = prompt3 | model2 |parser\n",
    "# branch_chain = RunnableBranch(\n",
    "#     (lambda x:x.sentiment=='positive',postivechain),\n",
    "#     (lambda x:x.sentiment==\"negative\",negativechain),\n",
    "#     RunnableLambda(lambda x:\"could not find sentiment\")\n",
    "# )\n",
    "# feedback = \"This is  a terrible product. It broke after one use and the customer service was unhelpful.\"\n",
    "# classification = classification_chain|branch_chain\n",
    "\n",
    "# classification.invoke({'feedback':feedback})\n",
    "# classification\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.runnables import RunnableBranch, RunnableLambda\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Literal\n",
    "\n",
    "# -------------------- ENV --------------------\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROK_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_KEY\")\n",
    "\n",
    "# -------------------- MODEL --------------------\n",
    "model = init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "\n",
    "# -------------------- SCHEMA --------------------\n",
    "class Feedback(BaseModel):\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"] = Field(\n",
    "        description=\"Sentiment of the feedback\"\n",
    "    )\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Feedback)\n",
    "\n",
    "# -------------------- PROMPTS --------------------\n",
    "classification_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "Classify the sentiment of the feedback as positive, negative, or neutral.\n",
    "\n",
    "Return ONLY JSON.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Feedback: {feedback}\n",
    "\"\"\",\n",
    "    input_variables=[\"feedback\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    },\n",
    ")\n",
    "\n",
    "positive_prompt = PromptTemplate(\n",
    "    template=\"Write an appropriate response to this positive feedback:\\n{feedback}\",\n",
    "    input_variables=[\"feedback\"],\n",
    ")\n",
    "\n",
    "negative_prompt = PromptTemplate(\n",
    "    template=\"Write an appropriate response to this negative feedback:\\n{feedback}\",\n",
    "    input_variables=[\"feedback\"],\n",
    ")\n",
    "\n",
    "neutral_prompt = PromptTemplate(\n",
    "    template=\"Write an appropriate response to this neutral feedback:\\n{feedback}\",\n",
    "    input_variables=[\"feedback\"],\n",
    ")\n",
    "\n",
    "# -------------------- CHAINS --------------------\n",
    "classification_chain = classification_prompt | model | parser\n",
    "\n",
    "positive_chain = positive_prompt | model\n",
    "negative_chain = negative_prompt | model\n",
    "neutral_chain = neutral_prompt | model\n",
    "\n",
    "# Helper → reattach feedback after classification\n",
    "def attach_feedback(sentiment_output):\n",
    "    return {\n",
    "        \"sentiment\": sentiment_output[\"sentiment\"],\n",
    "        \"feedback\": original_feedback\n",
    "    }\n",
    "\n",
    "attach_feedback_chain = RunnableLambda(attach_feedback)\n",
    "\n",
    "# -------------------- BRANCH --------------------\n",
    "branch_chain = RunnableBranch(\n",
    "    (\n",
    "        lambda x: x[\"sentiment\"] == \"positive\",\n",
    "        RunnableLambda(lambda x: {\"feedback\": x[\"feedback\"]})\n",
    "        | positive_chain,\n",
    "    ),\n",
    "    (\n",
    "        lambda x: x[\"sentiment\"] == \"negative\",\n",
    "        RunnableLambda(lambda x: {\"feedback\": x[\"feedback\"]})\n",
    "        | negative_chain,\n",
    "    ),\n",
    "    (\n",
    "        lambda x: x[\"sentiment\"] == \"neutral\",\n",
    "        RunnableLambda(lambda x: {\"feedback\": x[\"feedback\"]})\n",
    "        | neutral_chain,\n",
    "    ),\n",
    "    RunnableLambda(lambda x: \"Could not detect sentiment.\"),\n",
    ")\n",
    "\n",
    "# -------------------- FULL CHAIN --------------------\n",
    "original_feedback = (\n",
    "    \"This is a terrible product. It broke after one use \"\n",
    "    \"and the customer service was unhelpful.\"\n",
    ")\n",
    "\n",
    "chain = classification_chain | attach_feedback_chain | branch_chain\n",
    "\n",
    "# -------------------- RUN --------------------\n",
    "result = chain.invoke({\"feedback\": original_feedback})\n",
    "\n",
    "print(result.content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e60eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
