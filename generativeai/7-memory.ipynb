{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "826db8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROK_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f5e26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "agent = create_agent(model=\"groq:qwen/qwen3-32b\",checkpointer =InMemorySaver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6eeacec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for maintain the session we have to create a thread use this whenever we use the  inmemorysaver in llm\n",
    "config={\"configurable\":{\"thread_id\":\"test_1\"}}\n",
    "config1={\"configurable\":{\"thread_id\":\"test_2\"}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "557fe9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Hey my name is Sanjay!', additional_kwargs={}, response_metadata={}, id='e8bd5c08-0932-4f27-bdee-378e8a0798d8'),\n",
       "  AIMessage(content=\"<think>\\nOkay, the user introduced himself as Sanjay. I should respond in a friendly and welcoming manner. Let me start by greeting him back and asking how I can assist. Keep it simple and open-ended to encourage him to share what he needs help with.\\n\\nI need to make sure the response is warm and not too formal. Maybe add an emoji to keep it friendly. Also, avoid any technical jargon. Just a straightforward, cheerful reply. Let me check for any errors. Yeah, that should work.\\n</think>\\n\\nHello Sanjay! ðŸ˜Š How can I assist you today? Whether you have questions, need help with something specific, or just want to chat, I'm here for you!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 143, 'prompt_tokens': 15, 'total_tokens': 158, 'completion_time': 0.280669975, 'completion_tokens_details': None, 'prompt_time': 0.000471183, 'prompt_tokens_details': None, 'queue_time': 0.055384213, 'total_time': 0.281141158}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c1d79-dd28-7f62-a3af-e17b1167e9d8-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 15, 'output_tokens': 143, 'total_tokens': 158})]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "agent = create_agent(model=\"groq:qwen/qwen3-32b\",checkpointer = InMemorySaver())\n",
    "checkresponse = agent.invoke({\"messages\":[HumanMessage(content=\"Hey my name is Sanjay!\")]},config=config)\n",
    "checkresponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d08976ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='HI What is my name', additional_kwargs={}, response_metadata={}, id='6099afac-5e6c-4593-88df-a4b3ef0a74c6'),\n",
       "  AIMessage(content='<think>\\nOkay, the user is asking, \"HI What is my name.\" Let me start by understanding the context here. They\\'re greeting me, so a friendly response is appropriate. The key part is \"What is my name.\" I need to check if they\\'ve previously provided their name in the conversation history.\\n\\nLooking back at the conversation history, there\\'s no prior mention of the user sharing their name. My response should acknowledge their greeting and ask for their name. It\\'s important to be polite and inviting. Maybe something like, \"Hi there! ðŸ‘‹ I\\'m Qwen. I don\\'t know your name yetâ€”would you like to share it with me?\" That way, I\\'m being helpful and encouraging them to provide the information. I should also make sure to keep the tone positive and open to make them feel comfortable. No need to assume any prior information since there\\'s none in the history. Let\\'s go with that.\\n</think>\\n\\nHi there! ðŸ‘‹ I\\'m Qwen. I don\\'t know your name yetâ€”would you like to share it with me? I\\'d be happy to address you by it in our conversation!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 232, 'prompt_tokens': 13, 'total_tokens': 245, 'completion_time': 0.560404166, 'completion_tokens_details': None, 'prompt_time': 0.000344815, 'prompt_tokens_details': None, 'queue_time': 0.055387215, 'total_time': 0.560748981}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c1d79-f366-7f12-af48-d55478488085-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 13, 'output_tokens': 232, 'total_tokens': 245})]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkresponsess = agent.invoke({\"messages\":[HumanMessage(content=\"HI What is my name\")]},config=config1)\n",
    "checkresponsess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ddff4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
